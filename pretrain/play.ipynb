{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f391e49f-c01a-4d48-a437-55b9d146df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class TinyllmRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        \"\"\" æ—‹è½¬ä½ç½®ç¼–ç \n",
    "            - dim (int): æ—‹è½¬åµŒå…¥çš„ç»´åº¦å¤§å°ã€‚\n",
    "            - max_position_embeddings (int): é¢„è®¡ç®—çš„æœ€å¤§ä½ç½®åµŒå…¥æ•°ï¼Œé»˜è®¤ä¸º2048ã€‚\n",
    "            - base (int): ç”¨äºè®¡ç®—é€†é¢‘ç‡çš„åŸºæœ¬é¢‘ç‡ï¼Œé»˜è®¤ä¸º10000ã€‚\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        # è®¡ç®—é€†é¢‘ç‡å€¼ï¼Œå¹¶å°†å…¶æ³¨å†Œä¸ºæ¨¡å‹çš„ç¼“å†²åŒº\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2, dtype=torch.int64).float().to(device) / self.dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "        # ä¸ºäº†æ”¯æŒ`torch.jit.trace`åŠŸèƒ½ï¼Œç«‹å³è®¡ç®—é¢„å­˜å‚¨çš„ä½™å¼¦å’Œæ­£å¼¦ç¼“å­˜\n",
    "        self._set_cos_sin_cache(\n",
    "            seq_len=max_position_embeddings, device=self.inv_freq.device, dtype=torch.get_default_dtype()\n",
    "        )\n",
    "\n",
    "    def _set_cos_sin_cache(self, seq_len, device, dtype):\n",
    "        \"\"\" é¢„è®¡ç®—çš„ä½™å¼¦å’Œæ­£å¼¦ç¼“å­˜\n",
    "        \"\"\"\n",
    "        self.max_seq_len_cached = seq_len\n",
    "        # åˆ›å»ºä¸€ä¸ªä»0åˆ°æœ€å¤§åºåˆ—é•¿åº¦-1çš„æ•´æ•°å¼ é‡ï¼Œä¸ inv_freq å…·æœ‰ç›¸åŒçš„è®¾å¤‡å’Œæ•°æ®ç±»å‹\n",
    "        t = torch.arange(self.max_seq_len_cached, device=device, dtype=torch.int64).type_as(self.inv_freq)\n",
    "\n",
    "        # è®¡ç®—æ¯ä¸ªä½ç½®ä¸æ¯ä¸ªç»´åº¦çš„é¢‘ç‡ï¼Œå½¢æˆé¢‘è°±çŸ©é˜µ\n",
    "        freqs = torch.outer(t, self.inv_freq)\n",
    "        \n",
    "        # ä¸åŒäºè®ºæ–‡ä¸­çš„å®ç°ï¼Œè¿™é‡Œé‡‡ç”¨äº†ä¸åŒçš„æ’åˆ—æ–¹å¼ä»¥è·å¾—ç›¸åŒçš„è®¡ç®—ç»“æœ\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos().to(dtype), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin().to(dtype), persistent=False)\n",
    "\n",
    "    def forward(self, x, seq_len=None):\n",
    "        # x: [bs, num_attention_heads, seq_len, head_size]\n",
    "        if seq_len > self.max_seq_len_cached:\n",
    "            self._set_cos_sin_cache(seq_len=seq_len, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        return (\n",
    "            self.cos_cached[:seq_len].to(dtype=x.dtype),\n",
    "            self.sin_cached[:seq_len].to(dtype=x.dtype),\n",
    "        )\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\" æ—‹è½¬è¾“å…¥ä¸€åŠçš„ hidden dim\n",
    "    \"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "# Copied from transformers.models.mistral.modeling_mistral.apply_rotary_pos_emb\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
    "    \"\"\" åœ¨ qk åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç \n",
    "\n",
    "    Args:\n",
    "        q (`torch.Tensor`): q\n",
    "        k (`torch.Tensor`): k\n",
    "        cos (`torch.Tensor`): æ—‹è½¬ä½ç½®åµŒå…¥çš„ä½™å¼¦éƒ¨åˆ†\n",
    "        sin (`torch.Tensor`): æ—‹è½¬ä½ç½®åµŒå…¥çš„æ­£å¼¦éƒ¨åˆ†\n",
    "        position_ids (`torch.Tensor`): ä¸qå’Œkå¯¹åº”ä½ç½®çš„æ ‡è®°ç´¢å¼•ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤„ç†KVç¼“å­˜æ—¶ï¼Œå¯ä»¥ä½¿ç”¨åç§»è¿‡çš„ä½ç½®IDã€‚\n",
    "        unsqueeze_dim (`int`, *optional*, defaults to 1): 'unsqueeze_dim' å‚æ•°æŒ‡å®šäº†æ²¿å“ªä¸ªç»´åº¦å¯¹ cos[position_ids] \n",
    "            å’Œ sin[position_ids] è¿›è¡Œæ‰©å±•ï¼Œä»¥ä¾¿å®ƒä»¬èƒ½å¤Ÿé€‚å½“åœ°å¹¿æ’­åˆ° q å’Œ k çš„ç»´åº¦ä¸Šã€‚\n",
    "            ä¾‹å¦‚ï¼Œæ³¨æ„ cos[position_ids] å’Œ sin[position_ids] å…·æœ‰å½¢çŠ¶ [batch_size, seq_len, head_dim]ã€‚\n",
    "            é‚£ä¹ˆï¼Œå¦‚æœ q å’Œ k çš„å½¢çŠ¶åˆ†åˆ«ä¸º [batch_size, heads, seq_len, head_dim]ï¼Œ\n",
    "            åˆ™è®¾ç½® unsqueeze_dim=1 å¯ä½¿ cos[position_ids] å’Œ sin[position_ids] å¯ä»¥å¹¿æ’­åˆ° q å’Œ k çš„å½¢çŠ¶ä¸Šã€‚\n",
    "            åŒæ ·åœ°ï¼Œå¦‚æœ q å’Œ k çš„å½¢çŠ¶ä¸º [batch_size, seq_len, heads, head_dim]ï¼Œåˆ™åº”å°† unsqueeze_dim è®¾ç½®ä¸º 2\n",
    "    Returns:\n",
    "        åŒ…å«ä½¿ç”¨æ—‹è½¬ä½ç½®åµŒå…¥å˜æ¢åçš„qå’Œkå¼ é‡çš„ `tuple(torch.Tensor)`ã€‚\n",
    "    \"\"\"\n",
    "    # print(\"ori cos: \", cos.shape)\n",
    "    cos = cos[position_ids].unsqueeze(unsqueeze_dim)\n",
    "    sin = sin[position_ids].unsqueeze(unsqueeze_dim)\n",
    "\n",
    "    # print(\"q: \", q.shape)\n",
    "    # print(\"cos: \", cos.shape)\n",
    "    # print(\"sin: \", sin.shape)\n",
    "    # print(\"rotate_half: \", rotate_half(q).shape)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7c8ef-b766-45fd-ba73-060b6003674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k = torch.randn(4, 4, 12, 16), torch.randn(4, 4, 6, 16) # (bs, n_head, seq_len, n_dim)\n",
    "rotary_emb = TinyllmRotaryEmbedding(dim=16)\n",
    "cos, sin = rotary_emb(q, seq_len=4)\n",
    "q, k = apply_rotary_pos_emb(q, k, cos, sin, unsqueeze_dim=2)\n",
    "q.shape, k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2922a-0f09-45cc-91d3-9746eb9349b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(12, 16)[None].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0391cb16-3cb6-4283-849d-963ba1ec4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c381d-b936-4498-84f4-7cbf17b1cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrain import load_model_tokenizer\n",
    "\n",
    "\n",
    "tokenizer, model = load_model_tokenizer(tokenizer_name='Qwen/Qwen3-0.6B', seq_len=1024, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf224b-4d27-48f2-a6c8-a840d5639e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrain import sample\n",
    "sample(tokenizer, model, 'ä¸­å›½é¦–éƒ½æ˜¯å“ª?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c9d5d-24b8-4d53-a7ee-3350ec680072",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(tokenizer, num_proc=args.ds_num_proc, seq_len=args.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c6167-b669-4b5a-8d6b-557c3511f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor([2, 4]).ne(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24dc9e-183c-49da-80fb-d5c9ac9ceb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"12121333\".split('<|start|>assistant', maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd47e0-b1fa-4791-93ea-8d33e4a9f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# print(tokenizer.max_length)\n",
    "# Example messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi, who are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm an AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's your job?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Helping humans solve problems.\"}\n",
    "]\n",
    "\n",
    "# Convert to tokenized input\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True,  enable_thinking=False)\n",
    "\n",
    "print(prompt)\n",
    "# # Tokenize\n",
    "tokenized = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Create a batch format expected by the collator\n",
    "batch = [{\n",
    "    \"input_ids\": tokenized[\"input_ids\"][0],\n",
    "    \"attention_mask\": tokenized[\"attention_mask\"][0]\n",
    "}]\n",
    "\n",
    "# Use the collator to mask non-assistant tokens\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    tokenizer=tokenizer,\n",
    "    instruction_template=\"<|im_start|>user\",  # å¼€å§‹ loss çš„ä½ç½®\n",
    "    response_template=\"<|im_start|>assistant\",  # å¦‚æœä½ æƒ³ä» assistant å¼€å§‹ä¸€ç›´ç®— lossï¼Œå¯ä»¥çœç•¥\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "collated = collator(batch)\n",
    "\n",
    "# Show input_ids and labels (masked)\n",
    "print(\"\\nğŸ”¹ Tokens:\")\n",
    "print([tokenizer.decode([id]) for id in collated['input_ids'][0]])\n",
    "\n",
    "print(\"\\nğŸ”¹ Labels (for loss):\")\n",
    "for token_id, label_id in zip(collated[\"input_ids\"][0], collated[\"labels\"][0]):\n",
    "    token = tokenizer.decode([token_id.item()])\n",
    "    label = tokenizer.decode([label_id.item()]) if label_id != -100 else \"MASKED\"\n",
    "    print(f\"{token!r:20} -> {label!r}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a98d27-792c-47b7-a768-f9410f7e5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Example chat\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is AI?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"AI stands for Artificial Intelligence.\"}\n",
    "]\n",
    "\n",
    "# Apply template and tokenize directly\n",
    "out = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,            # ğŸ”¸ This returns tokenized output (not a string)\n",
    "    return_tensors=\"pt\"       # ğŸ”¸ This returns PyTorch tensors\n",
    ")\n",
    "\n",
    "print(out)                 # <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
    "# print(out.keys())               # dict_keys(['input_ids', 'attention_mask'])\n",
    "print(out[\"input_ids\"][0].shape)   # e.g., torch.Size([1, 50])\n",
    "print(tokenizer.decode(out[\"input_ids\"][0]))  # Decode to see result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed92d5-2e2d-41bd-9711-8a6ae90c0697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
