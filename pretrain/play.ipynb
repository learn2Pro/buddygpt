{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f391e49f-c01a-4d48-a437-55b9d146df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class TinyllmRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        \"\"\" 旋转位置编码\n",
    "            - dim (int): 旋转嵌入的维度大小。\n",
    "            - max_position_embeddings (int): 预计算的最大位置嵌入数，默认为2048。\n",
    "            - base (int): 用于计算逆频率的基本频率，默认为10000。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        # 计算逆频率值，并将其注册为模型的缓冲区\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2, dtype=torch.int64).float().to(device) / self.dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "        # 为了支持`torch.jit.trace`功能，立即计算预存储的余弦和正弦缓存\n",
    "        self._set_cos_sin_cache(\n",
    "            seq_len=max_position_embeddings, device=self.inv_freq.device, dtype=torch.get_default_dtype()\n",
    "        )\n",
    "\n",
    "    def _set_cos_sin_cache(self, seq_len, device, dtype):\n",
    "        \"\"\" 预计算的余弦和正弦缓存\n",
    "        \"\"\"\n",
    "        self.max_seq_len_cached = seq_len\n",
    "        # 创建一个从0到最大序列长度-1的整数张量，与 inv_freq 具有相同的设备和数据类型\n",
    "        t = torch.arange(self.max_seq_len_cached, device=device, dtype=torch.int64).type_as(self.inv_freq)\n",
    "\n",
    "        # 计算每个位置与每个维度的频率，形成频谱矩阵\n",
    "        freqs = torch.outer(t, self.inv_freq)\n",
    "        \n",
    "        # 不同于论文中的实现，这里采用了不同的排列方式以获得相同的计算结果\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos().to(dtype), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin().to(dtype), persistent=False)\n",
    "\n",
    "    def forward(self, x, seq_len=None):\n",
    "        # x: [bs, num_attention_heads, seq_len, head_size]\n",
    "        if seq_len > self.max_seq_len_cached:\n",
    "            self._set_cos_sin_cache(seq_len=seq_len, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        return (\n",
    "            self.cos_cached[:seq_len].to(dtype=x.dtype),\n",
    "            self.sin_cached[:seq_len].to(dtype=x.dtype),\n",
    "        )\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\" 旋转输入一半的 hidden dim\n",
    "    \"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "# Copied from transformers.models.mistral.modeling_mistral.apply_rotary_pos_emb\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
    "    \"\"\" 在 qk 应用旋转位置编码\n",
    "\n",
    "    Args:\n",
    "        q (`torch.Tensor`): q\n",
    "        k (`torch.Tensor`): k\n",
    "        cos (`torch.Tensor`): 旋转位置嵌入的余弦部分\n",
    "        sin (`torch.Tensor`): 旋转位置嵌入的正弦部分\n",
    "        position_ids (`torch.Tensor`): 与q和k对应位置的标记索引。例如，在处理KV缓存时，可以使用偏移过的位置ID。\n",
    "        unsqueeze_dim (`int`, *optional*, defaults to 1): 'unsqueeze_dim' 参数指定了沿哪个维度对 cos[position_ids] \n",
    "            和 sin[position_ids] 进行扩展，以便它们能够适当地广播到 q 和 k 的维度上。\n",
    "            例如，注意 cos[position_ids] 和 sin[position_ids] 具有形状 [batch_size, seq_len, head_dim]。\n",
    "            那么，如果 q 和 k 的形状分别为 [batch_size, heads, seq_len, head_dim]，\n",
    "            则设置 unsqueeze_dim=1 可使 cos[position_ids] 和 sin[position_ids] 可以广播到 q 和 k 的形状上。\n",
    "            同样地，如果 q 和 k 的形状为 [batch_size, seq_len, heads, head_dim]，则应将 unsqueeze_dim 设置为 2\n",
    "    Returns:\n",
    "        包含使用旋转位置嵌入变换后的q和k张量的 `tuple(torch.Tensor)`。\n",
    "    \"\"\"\n",
    "    # print(\"ori cos: \", cos.shape)\n",
    "    cos = cos[position_ids].unsqueeze(unsqueeze_dim)\n",
    "    sin = sin[position_ids].unsqueeze(unsqueeze_dim)\n",
    "\n",
    "    # print(\"q: \", q.shape)\n",
    "    # print(\"cos: \", cos.shape)\n",
    "    # print(\"sin: \", sin.shape)\n",
    "    # print(\"rotate_half: \", rotate_half(q).shape)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7c8ef-b766-45fd-ba73-060b6003674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k = torch.randn(4, 4, 12, 16), torch.randn(4, 4, 6, 16) # (bs, n_head, seq_len, n_dim)\n",
    "rotary_emb = TinyllmRotaryEmbedding(dim=16)\n",
    "cos, sin = rotary_emb(q, seq_len=4)\n",
    "q, k = apply_rotary_pos_emb(q, k, cos, sin, unsqueeze_dim=2)\n",
    "q.shape, k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2922a-0f09-45cc-91d3-9746eb9349b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(12, 16)[None].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0391cb16-3cb6-4283-849d-963ba1ec4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c381d-b936-4498-84f4-7cbf17b1cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrain import load_model_tokenizer\n",
    "\n",
    "\n",
    "tokenizer, model = load_model_tokenizer(tokenizer_name='Qwen/Qwen3-0.6B', seq_len=1024, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf224b-4d27-48f2-a6c8-a840d5639e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrain import sample\n",
    "sample(tokenizer, model, '中国首都是哪?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c9d5d-24b8-4d53-a7ee-3350ec680072",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(tokenizer, num_proc=args.ds_num_proc, seq_len=args.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c6167-b669-4b5a-8d6b-557c3511f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor([2, 4]).ne(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24dc9e-183c-49da-80fb-d5c9ac9ceb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"12121333\".split('<|start|>assistant', maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd47e0-b1fa-4791-93ea-8d33e4a9f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# print(tokenizer.max_length)\n",
    "# Example messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi, who are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm an AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's your job?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Helping humans solve problems.\"}\n",
    "]\n",
    "\n",
    "# Convert to tokenized input\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True,  enable_thinking=False)\n",
    "\n",
    "print(prompt)\n",
    "# # Tokenize\n",
    "tokenized = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Create a batch format expected by the collator\n",
    "batch = [{\n",
    "    \"input_ids\": tokenized[\"input_ids\"][0],\n",
    "    \"attention_mask\": tokenized[\"attention_mask\"][0]\n",
    "}]\n",
    "\n",
    "# Use the collator to mask non-assistant tokens\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    tokenizer=tokenizer,\n",
    "    instruction_template=\"<|im_start|>user\",  # 开始 loss 的位置\n",
    "    response_template=\"<|im_start|>assistant\",  # 如果你想从 assistant 开始一直算 loss，可以省略\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "collated = collator(batch)\n",
    "\n",
    "# Show input_ids and labels (masked)\n",
    "print(\"\\n🔹 Tokens:\")\n",
    "print([tokenizer.decode([id]) for id in collated['input_ids'][0]])\n",
    "\n",
    "print(\"\\n🔹 Labels (for loss):\")\n",
    "for token_id, label_id in zip(collated[\"input_ids\"][0], collated[\"labels\"][0]):\n",
    "    token = tokenizer.decode([token_id.item()])\n",
    "    label = tokenizer.decode([label_id.item()]) if label_id != -100 else \"MASKED\"\n",
    "    print(f\"{token!r:20} -> {label!r}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a98d27-792c-47b7-a768-f9410f7e5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Example chat\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is AI?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"AI stands for Artificial Intelligence.\"}\n",
    "]\n",
    "\n",
    "# Apply template and tokenize directly\n",
    "out = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,            # 🔸 This returns tokenized output (not a string)\n",
    "    return_tensors=\"pt\"       # 🔸 This returns PyTorch tensors\n",
    ")\n",
    "\n",
    "print(out)                 # <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
    "# print(out.keys())               # dict_keys(['input_ids', 'attention_mask'])\n",
    "print(out[\"input_ids\"][0].shape)   # e.g., torch.Size([1, 50])\n",
    "print(tokenizer.decode(out[\"input_ids\"][0]))  # Decode to see result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed92d5-2e2d-41bd-9711-8a6ae90c0697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
